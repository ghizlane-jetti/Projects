{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project1_Recommender_System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70o4V3gH2p05"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT6CEIiXtsqO"
      },
      "source": [
        "#Import  web scraping libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkQsU_Wv3XiW"
      },
      "source": [
        "## Sport"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o48AwsXdSrDI"
      },
      "source": [
        "#Sport Articles:\n",
        "\n",
        "Sport_Articles=[]\n",
        "Sport_Titles=[]\n",
        "URL = 'https://en.wikipedia.org/wiki/Sport' #URL of Sport Article\n",
        "page = requests.get(URL)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "results = soup.find(id='mw-content-text')\n",
        "title=soup.find(id=\"content\")\n",
        "title=title.find(\"h1\")\n",
        "t=title.get_text()  #Title of Article\n",
        "Sport_Titles.append(t)\n",
        "art = results.find_all('div', class_='mw-parser-output')\n",
        "s=\"\"\n",
        "for x in art:\n",
        "    for i in x.find_all('p'):\n",
        "      #Extract Article paragraphs\n",
        "      s=s+i.text\n",
        "Sport_Articles.append(s)\n",
        "results = soup.find_all('div',class_='div-col')\n",
        "l=[]\n",
        "txt=\"https://en.wikipedia.org/\"\n",
        "for x in results:\n",
        "  z=x.find_all('a', href=True)\n",
        "for i in z:\n",
        "  #URLS of related articles\n",
        "  l.append(txt+i['href'])\n",
        "\n",
        "#We will do the same thing as before to extract the related articles\n",
        "for link in l:\n",
        "  URL = link\n",
        "  page = requests.get(URL)\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  results = soup.find(id='mw-content-text')\n",
        "  title=soup.find(id=\"content\")\n",
        "  title=title.find(\"h1\")\n",
        "  t=title.get_text()  #Title of article\n",
        "  Sport_Titles.append(t)\n",
        "\n",
        "  art = results.find_all('div', class_='mw-parser-output')\n",
        "  s=\"\"\n",
        "  for x in art:\n",
        "    for i in x.find_all('p'):\n",
        "      #Extract Article paragraphs\n",
        "      s=s+i.text\n",
        "  Sport_Articles.append(s)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nadB5Wn18gfb"
      },
      "source": [
        "## Technology"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j31gvJ9P0xQc"
      },
      "source": [
        "#Technology Articles\n",
        "\n",
        "Tec_Articles=[]\n",
        "Tec_Titles=[]\n",
        "\n",
        "#URL of Technology Article\n",
        "URL = 'https://en.wikipedia.org/wiki/Technology'\n",
        "page = requests.get(URL)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "results = soup.find(id='mw-content-text')\n",
        "title=soup.find(id=\"content\")\n",
        "title=title.find(\"h1\") \n",
        "t=title.get_text()  #Title of article\n",
        "Tec_Titles.append(t)\n",
        "art = results.find_all('div', class_='mw-parser-output')\n",
        "s=\"\"\n",
        "for x in art:\n",
        "    for i in x.find_all('p'):\n",
        "      #Extract Article paragraphs\n",
        "      s=s+i.text\n",
        "Tec_Articles.append(s)\n",
        "results = soup.find_all('div',class_='div-col')\n",
        "l=[]\n",
        "txt=\"https://en.wikipedia.org/\"\n",
        "for x in results:\n",
        "  z=x.find_all('a', href=True)\n",
        "for i in z:\n",
        "  #URLS of related articles\n",
        "  l.append(txt+i['href'])\n",
        "\n",
        "#We will do the same thing as before to extract the 40 related articles\n",
        "for link in l[:40]:\n",
        "  URL = link\n",
        "  page = requests.get(URL)\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  results = soup.find(id='mw-content-text')\n",
        "  title=soup.find(id=\"content\")\n",
        "  title=title.find(\"h1\")\n",
        "  t=title.get_text()   # Title of article \n",
        "  Tec_Titles.append(t)\n",
        "  art = results.find_all('div', class_='mw-parser-output')\n",
        "  s=\"\"\n",
        "  for x in art:\n",
        "    for i in x.find_all('p'):\n",
        "      #Extract paragraphs\n",
        "      s=s+i.text\n",
        "  Tec_Articles.append(s)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UTUvzFsLv-m"
      },
      "source": [
        "## Agriculture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29BkMOxHB087"
      },
      "source": [
        "#Agriculture articles\n",
        "\n",
        "Agr_Articles=[]\n",
        "Agr_Titles=[]\n",
        "URL = 'https://en.wikipedia.org/wiki/Agriculture' #URL of Agriculture Article\n",
        "page = requests.get(URL)\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "results = soup.find(id='mw-content-text')\n",
        "title=soup.find(id=\"content\")\n",
        "title=title.find(\"h1\")\n",
        "t=title.get_text()  #Title of article\n",
        "Agr_Titles.append(t)\n",
        "art = results.find_all('div', class_='mw-parser-output')\n",
        "s=\"\"\n",
        "for x in art:\n",
        "    for i in x.find_all('p'):\n",
        "      #Extract Article paragraphs\n",
        "      s=s+i.text\n",
        "Agr_Articles.append(s)\n",
        "results = soup.find_all('div',class_='div-col')\n",
        "l=[]\n",
        "#We will do the same thing as before to extract some related articles\n",
        "txt=\"https://en.wikipedia.org/\"\n",
        "for x in results:\n",
        "  z=x.find_all('a', href=True)\n",
        "for i in z:\n",
        "  #URLS of related articles\n",
        "  l.append(txt+i['href'])\n",
        "for link in l:\n",
        "  URL = link\n",
        "  page = requests.get(URL)\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  results = soup.find(id='mw-content-text')\n",
        "  title=soup.find(id=\"content\")\n",
        "  title=title.find(\"h1\")\n",
        "  t=title.get_text()   #Title of Article\n",
        "  Agr_Titles.append(t)\n",
        "  art = results.find_all('div', class_='mw-parser-output')\n",
        "  s=\"\"\n",
        "  for x in art:\n",
        "    for i in x.find_all('p'):\n",
        "      #Extract Article paragraphs\n",
        "      s=s+i.text\n",
        "  Agr_Articles.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oECDWSbHE1KX"
      },
      "source": [
        "## Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be0dIHDXuJ32",
        "outputId": "4bb94627-d57d-443e-f38e-c4be38e5e518"
      },
      "source": [
        "#Import libraries:\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi8sQg5REev9"
      },
      "source": [
        "#Put all articles in one list\n",
        "Articles = Agr_Articles+Tec_Articles+Sport_Articles\n",
        "\n",
        "#Put all titles in one list\n",
        "Titles = Agr_Titles + Tec_Titles + Sport_Titles\n",
        "\n",
        "#id for each article\n",
        "IDS=[i for i in range(len(Titles))]\n",
        "\n",
        "#Data Cleaning\n",
        "j=0\n",
        "for i in Articles:\n",
        "  #remove \\n\n",
        "   Articles[j]= i.replace('\\n','')\n",
        "   j=j+1\n",
        "\n",
        "j=0\n",
        "for i in Articles:   \n",
        "   #remove \\xa0\n",
        "   Articles[j]= i.replace(u'\\xa0', u' ')\n",
        "   j=j+1\n",
        "\n",
        "j=0\n",
        "for i in Articles:\n",
        "  #remove numbers between box brackets \n",
        "   Articles[j] = re.sub(r'[\\d]', '', i) \n",
        "   j=j+1\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "CsaCMa7uGTkk",
        "outputId": "5b8c2dac-8623-4683-d3cd-ce4be3bf08f5"
      },
      "source": [
        "list_of_art = list(zip(IDS,Titles, Articles))  \n",
        "df = pd.DataFrame(list_of_art, \n",
        "                  columns = ['id', 'Title','Article']) \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Agriculture</td>\n",
              "      <td>Agriculture is the science and art of cultivat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Aeroponics</td>\n",
              "      <td>Aeroponics is the process of growing plants in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Agricultural aircraft</td>\n",
              "      <td>An agricultural aircraft is an aircraft that h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Agricultural engineering</td>\n",
              "      <td>Agricultural engineering is the engineering of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Agricultural robot</td>\n",
              "      <td>An agricultural robot is a robot deployed for ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                            Article\n",
              "0   0  ...  Agriculture is the science and art of cultivat...\n",
              "1   1  ...  Aeroponics is the process of growing plants in...\n",
              "2   2  ...  An agricultural aircraft is an aircraft that h...\n",
              "3   3  ...  Agricultural engineering is the engineering of...\n",
              "4   4  ...  An agricultural robot is a robot deployed for ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsCLsorctpv2"
      },
      "source": [
        "#Remove punctuation\n",
        "def remove_punc(text):\n",
        "  no_punc=\"\".join([c for c in text if c not in string.punctuation])\n",
        "  return no_punc\n",
        "j=0\n",
        "for i in Articles:\n",
        "  Articles[j]=remove_punc(i)\n",
        "  j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhaf1-4wGVl"
      },
      "source": [
        "#Remove URLS from Articles\n",
        "def remove_URL(sample):\n",
        "    \"\"\"Remove URLs from a sample string\"\"\"\n",
        "    return re.sub(r\"http\\S+\", \"\", sample)\n",
        "\n",
        "j=0\n",
        "for i in Articles:\n",
        "  Articles[j]=remove_URL(i)\n",
        "  j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eT39u_Xusnp"
      },
      "source": [
        "#Remove special caracters\n",
        "def special_car(text):\n",
        "   no_spe=re.sub('[^A-Za-z]+', ' ', text)\n",
        "   return no_spe\n",
        "j=0\n",
        "for i in Articles:\n",
        "  Articles[j]=special_car(i)\n",
        "  j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlDi6_rBvYga"
      },
      "source": [
        "## Recommender System: Content Filtering \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnWJmNKa0T4U"
      },
      "source": [
        "Content-based filtering uses item features to recommend other items similar to what the user likes, based on their previous actions or explicit feedback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRa3bmkOvjmv"
      },
      "source": [
        "#Import libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN09vGBfQzjx",
        "outputId": "4260a192-e6ab-49bb-cf46-15a565b1365b"
      },
      "source": [
        "#Define a TF-IDF Vectorizer Object and remove all english stop words such as 'the', 'a'\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
        "tfidf_matrix = tfidf.fit_transform(Articles)\n",
        "\n",
        "#Output the shape of tfidf_matrix\n",
        "tfidf_matrix.shape\n",
        "#tfidf.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 20406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkJXoGT0R0DL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b58019b-b227-4083-81ca-da45e726c197"
      },
      "source": [
        "# Compute the cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "print(\"cosine_sim[0]= \",cosine_sim[0])\n",
        "print(\"shape \",cosine_sim.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine_sim[0]=  [1.         0.18627452 0.14648923 0.33032912 0.20652491 0.19951347\n",
            " 0.16919569 0.23793954 0.17115231 0.1018541  0.15454691 0.25177783\n",
            " 0.13441203 0.24298959 0.06218323 0.07608009 0.27959556 0.15641112\n",
            " 0.04706762 0.03797363 0.06964645 0.04971823 0.11377698 0.03246872\n",
            " 0.06803978 0.01302618 0.03259371 0.06247055 0.04649381 0.05931572\n",
            " 0.14717873 0.05781068 0.04677955 0.02291753 0.09476015 0.15320593\n",
            " 0.07901968 0.0723728  0.0318142  0.05024605 0.04811816 0.04240787\n",
            " 0.03859565 0.08191515 0.03568726 0.05382936 0.06691125 0.05330158\n",
            " 0.0570913  0.0454065  0.05592172 0.07758188 0.07566445 0.07121563\n",
            " 0.08204051 0.04955658 0.04095699 0.09846392 0.07638379 0.05545699\n",
            " 0.10001531 0.03533134 0.0481731  0.04454616 0.03536554 0.0497823\n",
            " 0.07316544 0.02356833 0.02162111 0.03090547 0.03341181 0.00890223\n",
            " 0.03774878 0.05162253 0.03806882 0.0499172  0.07531606 0.\n",
            " 0.04313616 0.02018146 0.06402124 0.02477628 0.02941114 0.02631792\n",
            " 0.01299331 0.03912061 0.03536554 0.03767342 0.06596671 0.0468367\n",
            " 0.06184879 0.08544886 0.00819987 0.03263283 0.02876795 0.0534067\n",
            " 0.0362726  0.0334596  0.04893887 0.         0.02470298]\n",
            "shape  (101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk2bgMwkh6OG"
      },
      "source": [
        "#Construct a reverse map of indices and article titles\n",
        "\n",
        "indices = pd.Series(df.index, index=df['Title']).drop_duplicates()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A86Mqvb5hXro",
        "outputId": "bb0a26ba-47db-424d-9bf6-34bfd0ac54a4"
      },
      "source": [
        "#Indices\n",
        "indices[90:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Title\n",
              "Sports marketing                            90\n",
              "Sports nutrition                            91\n",
              "List of sports terms named after people     92\n",
              "Athletic training                           93\n",
              "Athlete                                     94\n",
              "Sportswear                                  95\n",
              "Team sport                                  96\n",
              "Underwater sports                           97\n",
              "Women's sports                              98\n",
              "List of water sports                        99\n",
              "Winter sports                              100\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofkxNffokgjf"
      },
      "source": [
        "# Function that takes in article title as input and outputs most similar articles\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # Get the index of the article that matches the title\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Get the pairwsie similarity scores of all articles with that article\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the articles based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar articles\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the article indices\n",
        "    article_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar articles\n",
        "    return df['Title'].iloc[article_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5PjjNOfk4PB",
        "outputId": "f37f80f0-b980-4794-b22d-df8d4a7ceb9f"
      },
      "source": [
        "#Let's test with title = \"Women's sports\"\n",
        "get_recommendations(\"Women's sports\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58                    Sport\n",
              "90         Sports marketing\n",
              "62               Parasports\n",
              "66      International sport\n",
              "59       Sport of athletics\n",
              "96               Team sport\n",
              "70        Multi-sport event\n",
              "81              Sports club\n",
              "73            Olympic Games\n",
              "87    Sports governing body\n",
              "Name: Title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhC0S7pOz3s8"
      },
      "source": [
        "We get the 10 most similar articles to Women's sports Article "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-favYlRz6xv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}